---
title: "Tiesinė regresija"
author: "Milda Zarankaite"
date: "Sunday, March 13, 2016"
output: html_document
---
#Tiesinė regresija

Statistikos ir ekonomikos tyrimuose neretai siekiama ištirti reiškinių priklausomybę, pavyzdžiui:   
* Koks parduodamų ledų kiekis priklausomai nuo oro temperatūros?  
* Ar bakalaro darbo įvertinimas turi įtakos darbo užmokesčiui?  
* ...  
  
Šias priklausomybes galima nustatyti, sudarydami regresijos modelį. 
Regresija yra tiesinė, kai vienas kintamasis nuo kito priklauso tiesiškai. Bendriausias regresijos modelis, siejantis X ir Y  


$$Y={\alpha}+{\beta}X+e$$,   


kur $Y$ - priklausomas kintamasis,  
$X$ - nepriklausomas kintamasis,  
${\alpha}$ ir ${\beta}$ - konstantos,   
$e$ - atsitiktinė paklaida.   

**Tiesinė daugialypė regresija** tiriama, kai vieną priklausomąjį kintamąjį $Y$ sieja tiesinė priklausomybė su $n$ nepriklausomų kintamųjų $(X_1,X_2,..,X_n)$. Tuomet tiesinė daugialypė regresija išreiškiama:  


$$Y_i={\alpha}+{\beta}_1X_{2i}+{\beta}_2X_{2i}+...+{\beta}_kX_{ki}+e_i$$


čia $Y_i$ – kintamojo Y i-oji reikšmė, kurią norime prognozuoti esant fiksuotoms nepriklausomų kintamųjų reikšmėms $X_1=x_{1i}$, $...$ , $X_{k}=x_{ki}$ ; ${\alpha}$, ${\beta}_1$, ${\beta}_2$, ... , ${\beta}_k$ yra nežinomi koeficientai, $e_i$ -atsitiktinė paklaida.


?? Regresijos analizei naudojami **duomenys** - intervaliniai kintamieji :$(x_{1},y_{1})$, $(x_{2},y_{2})$, $...$ , $(x_{n},y_{n})$. 


[Mažiausių kvadratų metodu](https://en.wikipedia.org/wiki/Least_squares) rasdami tokius ${\alpha}$ ir ${\beta}$ įverčius $\hat{\alpha}$, $\hat{\beta}$, kad $\hat{y}(x)=\hat{\alpha}+\hat{\beta}x$ taškuose $x_i$ kuo mažiau skirtųsi nuo $y_i$, gauname **regresijos tiesės lygtį**.

Dydis $e_i=y_{i}-\hat{y}(x_i)=y_{i}-(\hat{\alpha}+\hat{\beta}x_i)$ vadinamas i-ąja liekamąja paklaida, $i=1,2,…,n$.

Viena pagrindinė tiesinių regresinių modelių nauda - priklausomojo kintamojo prognozė. T.y. atradę tiesinę priklausomybę, galime nustatyti, kaip keisis $Y$ reikšmė, pakeitus nepriklausomąjį kintamąjį - $X$ vienu vienetu.   

Daugiau informacijos apie tiesinius regresinius modelius galima rasti [wikipedia.org](https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_regression)

Šiame įraše, pateikiamas pavyzdys kaip altiekama išsami tiesinė regresija naudojantis statistine programa R.

###Pavyzdys  
Turimi duomenys -  nekilnojamojo turto (gyvenamųjų butų) kainos ir kaikurios jų charakteristikos. Tikslas - sumodeliuoti tiesinę regresiją prekyboms agentams, kad geriau suprastų kokią įtaką skirtingos charakteristikos daro galutinei kainai.

####1.Duomenys:  
1.1.Susipažįstama su duomenimis:
```{r, message=FALSE}
library("car")# instaliuojama analizei reikalinga "car" biblioteka
```
```{r, echo=FALSE}
setwd("~/Econometrics/Blogo irasas - task4")
datafull<-read.csv2("data.csv") 
head(datafull)
```
Pateikiamos charakteristikos: plotas, aukštas, garsoIzoliacija, silmosLaidumas, atstumasIkiPrekybosCentro. Tikrinama, galbūt kažkurie nepriklausomi kintamieji -  mūsų atveju yra charakteristikos - yra koreliuoti. Koreliacijos atveju, tie patys kintamieji, turi labai panašią įtaką kainai. Tai stebime iš bendro visų kintamųjų duomenų grafiko:
```{r,echo=FALSE}
plot(datafull)
```

1.2. Pastebima, kad 2 rodikliai - garsoIzoliacija ir silumosLaidumas - tiesiškai susiję, todėl tikrinama galima duomenų koreliacija. 
```{r}
cor(datafull)
```
Kadangi koreliacijos koeficientas tarp aptartų rodiklių labai didelis (arti 1) - rodikliai labai susiję, t.y. abu apibūdina buto izoliaciją. Tai reikškia, kad koeficientų įverčiai tikriausiai bus paslinkti. Siekiant panaikinti šią problemą reikia arba panaikinti vieną iš kintamųjų arba juos kažkaip sujungti.  
Sujungti (vienas iš būdų - skaičiuoti vidurkį) nepasirenkama, nes nenustatyta ar abiejų koeficienų duomenis apibūdina tie patys matavimo vienetai.
Išvada: ištrinami garsoIzoliacijos duomenys. SilumosLaidumas yra svarbesnis, daro įtaką gyventojų išlaidoms, t.y mokesčiams už šildymą.
```{r}
datafull$garsoIzoliacija<-NULL
```


**1.3. Tikrinamos išskirtys**  
Viena iš priežasčių, kodėl kuriami modeliai nėra tikslūs - duomenyse yra išskirčių. Jos iškreipia pagrindines duomenų charakteristikas, tokias kaip vidurkis, dispersija. Siekiant sukurti kuo tikslesnę regresiją, išskirtis rekomenduojama pašalinti.  
Sukuriamas modelis modIsskirtims ir braižomas kvantilių grafikas [Q-Q plot](http://www.r-bloggers.com/exploratory-data-analysis-quantile-quantile-plots-for-new-yorks-ozone-pollution-data/), kuris parodo reikšmių pasiskirstymą:
```{r}
modIsskirtims<-lm(kaina~+plotas+aukstas+silumosLaidumas+atstumasIkiPrekybosCentro, datafull)
qqPlot(modIsskirtims, id.n=2)
```

Pastebima, kad duomenyse yra išskirčių, tad duomenys tikrinami pagal "outlierTest" diganostiką:
```{r}
outlierTest(modIsskirtims)
```
Rezultatas: pagal Bonferonni p korekciją (p-value<0.05) - eilutėse 253 ir 254 stebimos išskirtys. 
Eilutes su duomenimis, kuriuose yra išskirtys - pašaliname. Sukuriami nauji duomenys pavadinimu "data", kurie bus naudojami tolimesnei analizei.
```{r}
data<-datafull[-c(253,254),] 
```

####2.Modelio kūrimas  
2.1 Sukuriamas tiesnis modelis nuo visų turimų kintamųjų
```{r}
mod1<-lm(kaina~+plotas+aukstas+silumosLaidumas+atstumasIkiPrekybosCentro, data)
summary(mod1)$coefficients
```
Iš summary lentelėje pateiktos p-value galime teigti, kad koeficientas prie kintamojo "atstumasIkiPrekybosCentro" yra nereikšmingas (H0: b4=0 - priimame), todėl jis pašalinamas.

2.2. Atnaujinamas mod2 ir tikrinamas jo kintamųjų reikšmingumas
```{r}
mod2<-update(mod1, kaina~plotas+aukstas+silumosLaidumas)
summary(mod2)
```
Kadangi likę įverčiai reikšmingi - tikriname modelio tikslumą. Toliau tikrinamos prielaidos, kurias turi atitikti modelis. 

####3.Modelio patikimumo parametrai  
3.1. "R-Squared":
```{r}
(summary(mod2))$r.squared #Kuo arčiau 1, tuo modelis patikimesnis. 
```
$R^2$ yra statistinis matas, kuris parodo, kaip duomenys yra "arti" regresinės tiesės. $R^2$ reikšmė yra intervale [0,1], tad kuo matas arčiau 1 - tuo regresinė tiesė labiau prisitaikiusi prie duomenų. 

3.2.[Multikolinearumo tikrinimas](http://www.statisticssolutions.com/multicollinearity/)  
Statistikoje multikolinearumas yra fenomenas, kuris nurodo, kad regresijoje 2 ar daugiau kintamųjų yra koreliuoti. Šios problemos  egzistavimą tikriname naudojant Various Inflation Factor: 
```{r}
vif(mod2)
```
Multikolinearumo problemos nėra. Taip teigiama, nes egzistuojančią vidinę koreliaciją parodo koeficientai, kurių reikšmė yra daugiau nei 10.   

3.3. [Homoskedastiškumo tikrinimas](http://www.statisticssolutions.com/homoscedasticity/)   
Homoskedastiškumas parodo, kad regresijos atsitiktinės paklaidos yra  visur vienodos.
Išbrėžiamos paklaidos:
```{r, echo=FALSE}
par(mfrow=c(1,1))
plot(mod2$res~mod2$fitted, main="Paklaidų išsibarstymas pagal reikšmes", col=2)
```

Kaip matome, paklaidos pasiskirsčiusios pagal vidurkį 0, daugiausia intervale (-5000,5000). Todėl spėjama, kad modelis - homoskedastiškas.  Tai dar tikrinama pagal Breuch-Pagan testą
```{r}
ncvTest(mod2)
```
Kadangi p>0.05, vadinasi, priimame testo H0 hipotezę, kuri teigia, kad modelis homoskedastiškas - visų stebėjimų paklaidų dispersija yra konstanta.

3.4. Tikrinamas liekanų normalumas
```{r, echo=FALSE}
histmod2<-hist(mod2$res, probability=TRUE, main="Liekanų histograma", ylab="Tankumas") #išbrėžiama histograma
lines(density(mod2$res), col=4, lwd=2) #liekanų tankio grafikas
```

Mėlyna linija šioje histogramoje parodo liekanų tankumą. Ji primena varpo formą, tad spėjama, kad liekanos pasiskirsčiusios normaliai. Prielaida dar tikrinama Shapiro testu:
```{r}
shapiro.test(mod2$res) 
```
Pagal shapiro.test p-value>0.05 priimame H0: liekanų paklaidos yra normalios

3.5.Tikinama [liekanų autokoreliacija](https://onlinecourses.science.psu.edu/stat501/node/359)  
Geram modeliui taip pat svarbu, kad liekanos nebūtų susiję tarpusavyje. Tai tikrina Durbin-Watson testas
```{r}
durbinWatsonTest(mod2)
```
Kadangi testo p-value>0.05, H0: nėra koreliacijos tarp liekanų priimame.  

Vadinasi, kadangi modelis atitinka šiuos kriterijus, galime teigti, kad teisingas modelis $kaina~+plotas+aukstas+silumosLaidumas$. 
Atitinkamai įverčiai parodo kaip pakitus vienam vienetui iš šių charakteristikų, pakinta kaina: 
$kaina=8035.8 + 600.33*plotas+3.18.23*aukstas+528.82*silumosLaidumas+e$  
Interpretacija: 1 kv.m padidėjimas padidina kainą 600,33eurais, kiekvienas papildomas aukštas kainą padidina 318,23 eurais, 1 vnt. šilumos laidumo koeficiento padidėjimas padidina kainą 528,82 eurais. Laisvasis narys - 8035,80 eurai gali būti papildomas išlaidos pvz.:notaro paslaugos, buto lokacija, viešojo transporto prieinamumas ir pan. 

* Naudoti informacijos šaltiniai:
[wikipedia.org](https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_regression)
[wordpress.com blogas](https://gpaukstaite.wordpress.com/2011/10/15/tiesine-regresija/)
